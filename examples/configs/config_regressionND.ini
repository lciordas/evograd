# NEAT Configuration File for N-Dimensional Function Approximation
# This file contains all configuration parameters needed
# when using the NEAT algorithm to approximate N-dimensional functions.
#
# Note: num_inputs will be dynamically set based on the problem dimensionality

[POPULATION_INIT]

# The number of individuals in each generation.
# For higher dimensions, consider increasing this value
population_size = 200

# The number of input nodes, through which the network receives inputs.
# This will be overridden by the trial to match the problem dimensionality
num_inputs = 2

# The number of output nodes, to which the network delivers outputs.
num_outputs = 1

# Specifies the initial connectivity of newly-created networks.
# Allowed values:
#   "none"      - no connections are initially present
#   "one-input" - one random input node is connected to all outputs nodes
#   "partial"   - a fraction of all possible connections are instantiate randomly
#   "full"      - connect all input nodes to all output nodes
# For N-D problems, "partial" or "full" may work better
initial_cxn_policy = partial

# The fraction of connections to instantiate (only applicable
# if the initial connection policy is "partial").
# Use "None" if not applicable.
initial_cxn_fraction = 0.5

[SPECIATION]
# Individuals whose genomic distance is less than this
# threshold are considered to be in the same species.
compatibility_threshold = 15.0

# The coefficient for the excess gene counts'
# contribution to the genomic distance.
# Usually set equal to 'distance_disjoint_coeff'.
distance_excess_coeff = 1.0

# The coefficient for the disjoint gene counts'
# contribution to the genomic distance.
# Usually set equal to 'distance_excess_coeff'.
distance_disjoint_coeff = 1.0

# The coefficient for scalar parameter (connection weight,
# node bias or gain) difference's contribution to the genomic
# distance (for homologous nodes or connections).
distance_params_coeff = 0.5

# Whether to include in the genomic distance the contribution
# coming from the difference in parameters of homologous nodes.
distance_includes_nodes = true

# Scaling factor for tanh activation distance calculation.
# When both nodes have legendre activation, distance = tanh(k * mean_coeff_diff).
# Higher k makes the distance more sensitive to coefficient differences.
activation_distance_k = 3.0

[FITNESS]
# Penalty coefficients applied as corrections to the example-specific fitness function.
# These encourage simpler networks by penalizing complexity. Set to 0.0 to disable.

# Penalty per node (beyond input/output nodes).
num_nodes_penalty = 0.0

# Penalty per enabled connection.
num_connections_penalty = 0.0

[REPRODUCTION]
# The number of most-fit individuals in each species that
# will be preserved as-is from one generation to the next.
elitism = 2

# The fraction of individuals allowed to reproduce in each species.
survival_threshold = 0.2

# The minimum number of individual per species after reproduction.
min_species_size = 2

# Number of episodes to average over for fitness evaluation.
# N/A in this case, as we are solving a deterministic problem.
num_episodes_average = 1

[STAGNATION]
# Species that have not shown improvement in more than this
# number of generations will be considered stagnant and removed.
max_stagnation_period = 20

# The number of species that will be protected from stagnation.
species_elitism = 2

[TERMINATION]
# Whether to use the fitness of the most recent
# generation as a criterion for stopping the run.
fitness_termination_check = true

# The function used to compute the termination criterion.
# Only applicable if 'fitness_termination_check' is 'True'.
# Allowed values:
#   "mean" calculate the mean fitness across the entire population
#   "max"  get the fitness of the fittest individual in the population
fitness_criterion = max

# The fitness value which when met or exceeded causes the run to end.
# Only applicable if 'fitness_termination_check' is 'True'.
# The value to be compared with this threshold is calculated according
# to 'fitness_criterion'.
fitness_threshold = 9.9

# The number of generations after which to stop the run.
# If 'fitness_termination_check' is 'True', the run may stop sooner.
# Consider increasing for complex N-D problems
max_number_generations = 500

[NODE]
# The activation function assigned to each node.
# For the list of all available choices, see the 'activation' module.
activation_initial = sigmoid

# The mean and standard deviation of the normal distributions
# used to initialize the 'bias' & 'gain' parameters for new nodes.
bias_init_mean  = 0.0
bias_init_stdev = 1.0
gain_init_mean  = 0.0
gain_init_stdev = 1.0

# The minimum and maximum allowed 'bias' and 'gain' values.
# Biases outside this range will be clamped to this range.
min_bias = -30.0
max_bias =  30.0
min_gain = -30.0
max_gain =  30.0

# The probability that mutation will replace the 'bias' and 'gain' of
# a node with a newly chosen random value (as if it were a new node).
bias_replace_prob = 0.1
gain_replace_prob = 0.0

# The probability that mutation will change the 'bias' and 'gain'
# of a node by adding a random value.
bias_perturb_prob = 0.7
gain_perturb_prob = 0.0

# The standard deviation of the zero-centered normal distributions
# from which a 'bias' and a 'gain' perturbation value is drawn.
bias_perturb_strength = 0.5
gain_perturb_strength = 0.0

# The probability that mutation will change the activation function
# of a node to a different activation function.
activation_mutate_prob = 0.0

# Which activation functions are available for mutation.
# Options:
#   "all"    - all available activations (fixed + learnable)
#   "fixed"  - only non-learnable activations (excludes legendre)
#   "list"   - comma-separated list (e.g., "sigmoid, tanh, relu")
activation_options = all

[CONNECTION]
# The mean and standard deviation of the normal distribution
# used to initialize the 'weight' parameter for new connections.
weight_init_mean = 0.0
weight_init_stdev = 1.0

# The minimum and maximum allowed 'weight' values.
# Biases outside this range will be clamped to this range.
min_weight = -30.0
max_weight =  30.0

# The probability that mutation will replace the 'weight' of a connection
# with a newly chosen random value (as if it were a new connection).
weight_replace_prob = 0.1

# The probability that mutation will change the 'weight'
# of a connection by adding a random value.
weight_perturb_prob = 0.8

# The standard deviation of the zero-centered normal distribution
# from which a 'weight' perturbation value is drawn.
weight_perturb_strength = 0.5

[STRUCTURAL_MUTATIONS]
# If this is 'True', only one structural mutation (the addition or removal
# of a node or connection) will be allowed per genome per generation.
single_structural_mutation = true

# The probability that mutation will add a new node (essentially replacing
# an existing connection, the enabled status of which will be set to False).
node_add_probability = 0.2

# The probability that mutation will delete an existing node (and all connections to it).
# This goes a bit against the original NEAT philosophy (start with a small network and
# continuously grow it, so keep its value to 0 unless you have a good reason not to).
node_delete_probability = 0

# The probability that mutation will add a connection between existing nodes
connection_add_probability = 0.5

# The probability that a mutation will enabled a currently
# disabled connection, or the other way around.
connection_enable_probability  = 0.01
connection_disable_probability = 0.01

# The probability that mutation will delete an existing connection (irrespective of
# whether currently enabled or disabled).
# This goes a bit against the original NEAT approach, which disables rather than delete
# connections, so keep its value to 0 unless you have a good reason not to).
connection_delete_probability = 0

[GRADIENT_DESCENT]
# Whether to apply gradient descent optimization to individuals.
enable_gradient = false

# Number of gradient descent steps per application.
gradient_steps = 1000

# Learning rate for gradient updates (step size for Adam optimizer).
learning_rate = 0.01

# Apply gradients every N generations (1 = every generation).
gradient_frequency = 1

# Which individuals to train with gradient descent.
# Allowed values: 'all', 'top_k', 'top_percent'
gradient_selection = all

# Number of top individuals to train (only applicable if gradient_selection='top_k').
gradient_top_k = 5

# Percentage of top individuals to train (only applicable if gradient_selection='top_percent').
gradient_top_percent = 0.1

# Whether to save gradient-optimized parameters back to the genome (Lamarckian evolution).
# If True, parameters learned through gradient descent are written back to the genome
# and can be inherited by offspring. If False, gradient descent only affects fitness
# evaluation but learned parameters are not inherited (Baldwin effect).
lamarckian_evolution = true